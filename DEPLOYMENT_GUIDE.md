# ğŸš€ GuÃ­a de Despliegue para Streamlit

Esta guÃ­a te ayudarÃ¡ a resolver los dos problemas principales para el despliegue:

1. **Archivo CSV muy grande (211MB > 100MB lÃ­mite GitHub)**
2. **Backend API requerido para funcionalidades completas**

## ğŸ“Š Problema 1: Dataset Grande

### SoluciÃ³n A: Git LFS (Recomendado para GitHub)

```bash
# 1. Instalar Git LFS
git lfs install

# 2. Configurar tracking (ya incluido en .gitattributes)
git lfs track "*.csv"
git lfs track "data/"

# 3. Agregar archivos
git add .gitattributes
git add data/spotify_dataset_sin_duplicados_4.csv
git commit -m "Add large dataset with LFS"
git push
```

### SoluciÃ³n B: Servicios en la Nube

#### Google Drive
1. Sube tu CSV a Google Drive
2. Haz click derecho â†’ "Obtener enlace" â†’ "Cualquiera con el enlace"
3. Copia el ID del archivo (entre `/d/` y `/view` en la URL)
4. En la app de Streamlit, usa la opciÃ³n "Descargar desde la nube"

#### Dropbox
1. Sube tu CSV a Dropbox
2. ObtÃ©n enlace de descarga directa (reemplaza `dl=0` por `dl=1`)
3. Ãšsalo en la opciÃ³n de descarga de la app

#### GitHub Releases
1. Ve a tu repositorio â†’ Releases â†’ Create new release
2. Sube el CSV como asset del release
3. Usa la URL de descarga directa

### SoluciÃ³n C: Dataset de Muestra
Para desarrollo/testing, la app puede generar un dataset de muestra con funcionalidad limitada.

## ğŸ”— Problema 2: Backend API

### OpciÃ³n 1: Deployment Local (Desarrollo)

```bash
# 1. Iniciar API automÃ¡ticamente
cd frontend-machine-learning/
./start_api.sh  # Linux/Mac
# o
start_api.bat   # Windows

# 2. Verificar que funciona
# API: http://localhost:8000
# Docs: http://localhost:8000/docs

# 3. Iniciar Streamlit
streamlit run app.py
```

### OpciÃ³n 2: Deployment Conjunto (ProducciÃ³n)

#### Para Streamlit Cloud:

1. **Crear `requirements.txt` completo:**
```txt
streamlit
pandas
requests
numpy
scikit-learn
fastapi
uvicorn
python-multipart
```

2. **Crear script de inicio combinado (`startup.sh`):**
```bash
#!/bin/bash
# Iniciar API en background
cd ml-project-models/
uvicorn api:app --host 0.0.0.0 --port 8000 &
cd ../frontend-machine-learning/

# Esperar que API inicie
sleep 10

# Iniciar Streamlit
streamlit run app.py --server.port 8501 --server.address 0.0.0.0
```

3. **Configurar Streamlit Cloud:**
   - Subir cÃ³digo a GitHub (con Git LFS para dataset)
   - En Streamlit Cloud, configurar startup command: `bash startup.sh`

#### Para Heroku:

1. **Crear `Procfile`:**
```
web: bash startup.sh
```

2. **Crear `runtime.txt`:**
```
python-3.9.18
```

3. **Configurar vars de entorno si es necesario**

#### Para Railway/Render:

1. **Railway:**
   - Conectar GitHub repo
   - Configurar start command: `bash startup.sh`
   - AÃ±adir variables de entorno si es necesario

2. **Render:**
   - Similar a Railway
   - Configurar build y start commands

### OpciÃ³n 3: APIs Separadas (Microservicios)

#### Backend API (FastAPI):
- Deploy en Heroku/Railway/Render
- Endpoint pÃºblico (ej: `https://tu-api.herokuapp.com`)

#### Frontend (Streamlit):
- Deploy en Streamlit Cloud
- Configurar `API_BASE_URL` para apuntar al backend pÃºblico

**Ejemplo de configuraciÃ³n:**
```python
# En utils/api_client.py
import os
API_BASE_URL = os.getenv("API_URL", "https://tu-api.herokuapp.com")
```

## ğŸ“ Estructura Recomendada para Deploy

```
proyecto/
â”œâ”€â”€ .gitattributes          # Para Git LFS
â”œâ”€â”€ requirements.txt        # Dependencias completas
â”œâ”€â”€ startup.sh             # Script de inicio conjunto
â”œâ”€â”€ README.md              # DocumentaciÃ³n
â”œâ”€â”€ frontend-machine-learning/
â”‚   â”œâ”€â”€ app.py             # App principal
â”‚   â”œâ”€â”€ start_api.sh       # Script de API (desarrollo)
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ api_manager.py  # Manejo de API
â”‚   â”‚   â”œâ”€â”€ data_manager.py # Manejo de datasets
â”‚   â”‚   â””â”€â”€ api_client.py   # Cliente API
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ spotify_dataset_sin_duplicados_4.csv  # Con LFS
â””â”€â”€ ml-project-models/
    â”œâ”€â”€ api.py             # FastAPI backend
    â”œâ”€â”€ requirements_api.txt
    â””â”€â”€ saved_models/
        â””â”€â”€ explicit_lyrics_classifier.pkl
```

## ğŸ”§ Comandos de Desarrollo

```bash
# 1. Desarrollo local
cd frontend-machine-learning/
./start_api.sh           # Terminal 1: API
streamlit run app.py     # Terminal 2: Frontend

# 2. Testing conjunto
bash startup.sh          # Inicia ambos servicios

# 3. Solo frontend (sin funcionalidades de ML)
streamlit run app.py     # La app manejarÃ¡ la ausencia de API
```

## ğŸŒ URLs de ProducciÃ³n

- **Frontend Streamlit:** `https://tu-app.streamlit.app`
- **Backend API:** `https://tu-api.herokuapp.com`
- **DocumentaciÃ³n API:** `https://tu-api.herokuapp.com/docs`

## ğŸ“ Checklist de Deploy

### Pre-deploy:
- [ ] Dataset subido con Git LFS o configurado descarga
- [ ] Modelo ML entrenado y guardado
- [ ] Variables de entorno configuradas
- [ ] Requirements.txt completo
- [ ] Scripts de inicio creados

### Post-deploy:
- [ ] API funciona: `{api_url}/health`
- [ ] Frontend carga correctamente
- [ ] Dataset se descarga/carga automÃ¡ticamente
- [ ] Funcionalidades de ML operativas
- [ ] Logs sin errores crÃ­ticos

## ğŸ› SoluciÃ³n de Problemas

### API no inicia:
```bash
# Verificar dependencias
pip install -r ml-project-models/requirements_api.txt

# Verificar modelo
ls ml-project-models/saved_models/

# Logs detallados
uvicorn api:app --log-level debug
```

### Dataset no carga:
- Verificar Git LFS: `git lfs ls-files`
- Verificar URLs de descarga
- Usar dataset de muestra para testing

### Streamlit Cloud issues:
- Verificar logs en el dashboard
- Reducir tamaÃ±o de dataset si es necesario
- Configurar secrets para URLs privadas
